{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHR9tt4YVgTj"
   },
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7EkZhjNsVe46"
   },
   "source": [
    "Run a multilayer perceptron (feed forward neural network) with two hidden layers and rectified linear nonlinearities on the iris dataset using the keras​ Sequential interface​. Include code for selecting regularization strength and number of hidden units using GridSearchCV and evaluation on an independent test-set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4S-cufIRxm12"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ubA5tyoZxtXZ",
    "outputId": "782425f3-f71e-4dfc-c0e5-fd0cbb4e3144"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "\n",
    "num_classes = len(set(y))\n",
    "\n",
    "import keras\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8-OK7IwXHur"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1EwM7TfXLjt"
   },
   "outputs": [],
   "source": [
    "def model(hidden_size_1, hidden_size_2, optimizer=\"adam\", C=1):\n",
    "    model = Sequential([\n",
    "        Dense(hidden_size_1, input_shape=(4,), kernel_regularizer=regularizers.l2(C)),\n",
    "        Activation('relu'),\n",
    "        Dense(hidden_size_2, kernel_regularizer=regularizers.l2(C)),\n",
    "        Activation('relu'),\n",
    "        Dense(3),\n",
    "        Activation('softmax'),\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer,loss=\"categorical_crossentropy\", \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgFpXQZiVwes"
   },
   "source": [
    "GridSearch the parameters of network to find out the best combination of parameters that achieves the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9641
    },
    "colab_type": "code",
    "id": "35lE4LqOXRXs",
    "outputId": "81caee79-e979-4b58-94eb-4f96de74b191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 1.6014 - acc: 0.3500\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 102us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7711 - acc: 0.3300\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "100/100 [==============================] - 0s 109us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6767 - acc: 0.3300\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "100/100 [==============================] - 0s 104us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6401 - acc: 0.3400\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "100/100 [==============================] - 0s 99us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.3546 - acc: 0.3400\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "100/100 [==============================] - 0s 116us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 1.9142 - acc: 0.3300\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "100/100 [==============================] - 0s 116us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 1.7260 - acc: 0.2500\n",
      "12/12 [==============================] - 0s 12ms/step\n",
      "100/100 [==============================] - 0s 124us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 1.7237 - acc: 0.3400\n",
      "12/12 [==============================] - 0s 14ms/step\n",
      "100/100 [==============================] - 0s 129us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 1.6068 - acc: 0.4500\n",
      "12/12 [==============================] - 0s 16ms/step\n",
      "100/100 [==============================] - 0s 129us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.6951 - acc: 0.3700\n",
      "12/12 [==============================] - 0s 19ms/step\n",
      "100/100 [==============================] - 0s 111us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.7137 - acc: 0.3900\n",
      "12/12 [==============================] - 0s 19ms/step\n",
      "100/100 [==============================] - 0s 111us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.8023 - acc: 0.4500\n",
      "12/12 [==============================] - 0s 20ms/step\n",
      "100/100 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.1074 - acc: 0.4200\n",
      "12/12 [==============================] - 0s 24ms/step\n",
      "100/100 [==============================] - 0s 129us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.6570 - acc: 0.5400\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "100/100 [==============================] - 0s 127us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 1.7010 - acc: 0.4800\n",
      "12/12 [==============================] - 0s 27ms/step\n",
      "100/100 [==============================] - 0s 138us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 1.6446 - acc: 0.3400\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "100/100 [==============================] - 0s 142us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.6714 - acc: 0.3600\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "100/100 [==============================] - 0s 134us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.8552 - acc: 0.3500\n",
      "12/12 [==============================] - 0s 33ms/step\n",
      "100/100 [==============================] - 0s 134us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.7335 - acc: 0.3500\n",
      "12/12 [==============================] - 0s 37ms/step\n",
      "100/100 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 1.8773 - acc: 0.3400\n",
      "12/12 [==============================] - 0s 38ms/step\n",
      "100/100 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 3.6349 - acc: 0.3500\n",
      "12/12 [==============================] - 0s 42ms/step\n",
      "100/100 [==============================] - 0s 129us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 3.6335 - acc: 0.2800\n",
      "12/12 [==============================] - 1s 42ms/step\n",
      "100/100 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.6673 - acc: 0.4000\n",
      "12/12 [==============================] - 1s 45ms/step\n",
      "100/100 [==============================] - 0s 131us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.6185 - acc: 0.4600\n",
      "12/12 [==============================] - 1s 48ms/step\n",
      "100/100 [==============================] - 0s 125us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 3.7745 - acc: 0.3900\n",
      "12/12 [==============================] - 1s 49ms/step\n",
      "100/100 [==============================] - 0s 143us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.4067 - acc: 0.4600\n",
      "12/12 [==============================] - 1s 52ms/step\n",
      "100/100 [==============================] - 0s 140us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.3663 - acc: 0.5900\n",
      "12/12 [==============================] - 1s 53ms/step\n",
      "100/100 [==============================] - 0s 129us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.3993 - acc: 0.2900\n",
      "12/12 [==============================] - 1s 56ms/step\n",
      "100/100 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.5096 - acc: 0.3400\n",
      "12/12 [==============================] - 1s 59ms/step\n",
      "100/100 [==============================] - 0s 122us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.3999 - acc: 0.4800\n",
      "12/12 [==============================] - 1s 61ms/step\n",
      "100/100 [==============================] - 0s 135us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 1.7325 - acc: 0.3400\n",
      "12/12 [==============================] - 1s 61ms/step\n",
      "100/100 [==============================] - 0s 148us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 1.7401 - acc: 0.4700\n",
      "12/12 [==============================] - 1s 64ms/step\n",
      "100/100 [==============================] - 0s 103us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 1.7348 - acc: 0.3200\n",
      "12/12 [==============================] - 1s 66ms/step\n",
      "100/100 [==============================] - 0s 158us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 1.8813 - acc: 0.3400\n",
      "12/12 [==============================] - 1s 65ms/step\n",
      "100/100 [==============================] - 0s 137us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 1.5673 - acc: 0.6700\n",
      "12/12 [==============================] - 1s 64ms/step\n",
      "100/100 [==============================] - 0s 156us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 4.4431 - acc: 0.4400\n",
      "12/12 [==============================] - 1s 65ms/step\n",
      "100/100 [==============================] - 0s 136us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 4.5224 - acc: 0.3400\n",
      "12/12 [==============================] - 1s 67ms/step\n",
      "100/100 [==============================] - 0s 132us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 4.4309 - acc: 0.4500\n",
      "12/12 [==============================] - 1s 69ms/step\n",
      "100/100 [==============================] - 0s 137us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 4.4530 - acc: 0.3400\n",
      "12/12 [==============================] - 1s 77ms/step\n",
      "100/100 [==============================] - 0s 125us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 4.4505 - acc: 0.4500\n",
      "12/12 [==============================] - 1s 79ms/step\n",
      "100/100 [==============================] - 0s 171us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6.1009 - acc: 0.6100\n",
      "12/12 [==============================] - 1s 78ms/step\n",
      "100/100 [==============================] - 0s 142us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 6.1289 - acc: 0.4300\n",
      "12/12 [==============================] - 1s 77ms/step\n",
      "100/100 [==============================] - 0s 148us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 6.0326 - acc: 0.4900\n",
      "12/12 [==============================] - 1s 81ms/step\n",
      "100/100 [==============================] - 0s 127us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 6.0389 - acc: 0.4500\n",
      "12/12 [==============================] - 1s 82ms/step\n",
      "100/100 [==============================] - 0s 144us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 6.0729 - acc: 0.3000\n",
      "12/12 [==============================] - 1s 84ms/step\n",
      "100/100 [==============================] - 0s 148us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 38.8282 - acc: 0.6400\n",
      "12/12 [==============================] - 1s 88ms/step\n",
      "100/100 [==============================] - 0s 127us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 40.0226 - acc: 0.3400\n",
      "12/12 [==============================] - 1s 89ms/step\n",
      "100/100 [==============================] - 0s 144us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 39.2832 - acc: 0.3400\n",
      "12/12 [==============================] - 1s 91ms/step\n",
      "100/100 [==============================] - 0s 143us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 40.4557 - acc: 0.3400\n",
      "12/12 [==============================] - 1s 96ms/step\n",
      "100/100 [==============================] - 0s 132us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 39.5142 - acc: 0.3300\n",
      "12/12 [==============================] - 1s 97ms/step\n",
      "100/100 [==============================] - 0s 144us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 64.3759 - acc: 0.3200\n",
      "12/12 [==============================] - 1s 101ms/step\n",
      "100/100 [==============================] - 0s 152us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 64.3915 - acc: 0.3200\n",
      "12/12 [==============================] - 1s 109ms/step\n",
      "100/100 [==============================] - 0s 165us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 63.5564 - acc: 0.3300\n",
      "12/12 [==============================] - 1s 114ms/step\n",
      "100/100 [==============================] - 0s 183us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 63.4522 - acc: 0.3300\n",
      "12/12 [==============================] - 1s 106ms/step\n",
      "100/100 [==============================] - 0s 159us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 64.9517 - acc: 0.3300\n",
      "12/12 [==============================] - 1s 109ms/step\n",
      "100/100 [==============================] - 0s 119us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 67.5857 - acc: 0.2700\n",
      "12/12 [==============================] - 1s 110ms/step\n",
      "100/100 [==============================] - 0s 157us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 67.1650 - acc: 0.3300\n",
      "12/12 [==============================] - 1s 114ms/step\n",
      "100/100 [==============================] - 0s 160us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 65.9247 - acc: 0.3300\n",
      "12/12 [==============================] - 1s 117ms/step\n",
      "100/100 [==============================] - 0s 126us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 66.0651 - acc: 0.3000\n",
      "12/12 [==============================] - 1s 121ms/step\n",
      "100/100 [==============================] - 0s 154us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 66.4360 - acc: 0.4100\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "100/100 [==============================] - 0s 186us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 64.7550 - acc: 0.3300\n",
      "12/12 [==============================] - 2s 127ms/step\n",
      "100/100 [==============================] - 0s 154us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 64.4675 - acc: 0.3300\n",
      "12/12 [==============================] - 2s 126ms/step\n",
      "100/100 [==============================] - 0s 151us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 37ms/step - loss: 65.7472 - acc: 0.3300\n",
      "12/12 [==============================] - 2s 129ms/step\n",
      "100/100 [==============================] - 0s 158us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 37ms/step - loss: 62.1651 - acc: 0.6400\n",
      "12/12 [==============================] - 2s 130ms/step\n",
      "100/100 [==============================] - 0s 154us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 63.5305 - acc: 0.3400\n",
      "12/12 [==============================] - 2s 135ms/step\n",
      "100/100 [==============================] - 0s 172us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 257.1308 - acc: 0.3300\n",
      "12/12 [==============================] - 2s 135ms/step\n",
      "100/100 [==============================] - 0s 142us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 255.3866 - acc: 0.3400\n",
      "12/12 [==============================] - 2s 147ms/step\n",
      "100/100 [==============================] - 0s 176us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 257.6320 - acc: 0.3300\n",
      "12/12 [==============================] - 2s 153ms/step\n",
      "100/100 [==============================] - 0s 168us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 258.2490 - acc: 0.3800\n",
      "12/12 [==============================] - 2s 143ms/step\n",
      "100/100 [==============================] - 0s 172us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 257.7413 - acc: 0.3300\n",
      "12/12 [==============================] - 2s 146ms/step\n",
      "100/100 [==============================] - 0s 172us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 337.9035 - acc: 0.3400\n",
      "12/12 [==============================] - 2s 150ms/step\n",
      "100/100 [==============================] - 0s 173us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 338.8022 - acc: 0.3400\n",
      "12/12 [==============================] - 2s 153ms/step\n",
      "100/100 [==============================] - 0s 186us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 338.1972 - acc: 0.3100\n",
      "12/12 [==============================] - 2s 169ms/step\n",
      "100/100 [==============================] - 0s 201us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 49ms/step - loss: 337.1622 - acc: 0.2700\n",
      "12/12 [==============================] - 2s 172ms/step\n",
      "100/100 [==============================] - 0s 162us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 45ms/step - loss: 336.6478 - acc: 0.3400\n",
      "12/12 [==============================] - 2s 160ms/step\n",
      "100/100 [==============================] - 0s 179us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 66.9971 - acc: 0.3400\n",
      "12/12 [==============================] - 2s 163ms/step\n",
      "100/100 [==============================] - 0s 171us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 67.9907 - acc: 0.3300\n",
      "12/12 [==============================] - 2s 168ms/step\n",
      "100/100 [==============================] - 0s 150us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 67.1883 - acc: 0.6500\n",
      "12/12 [==============================] - 2s 166ms/step\n",
      "100/100 [==============================] - 0s 168us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 67.7310 - acc: 0.3600\n",
      "12/12 [==============================] - 2s 182ms/step\n",
      "100/100 [==============================] - 0s 189us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 67.1453 - acc: 0.3400\n",
      "12/12 [==============================] - 2s 172ms/step\n",
      "100/100 [==============================] - 0s 175us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 337.8477 - acc: 0.3900\n",
      "12/12 [==============================] - 2s 174ms/step\n",
      "100/100 [==============================] - 0s 149us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 337.8265 - acc: 0.3400\n",
      "12/12 [==============================] - 2s 177ms/step\n",
      "100/100 [==============================] - 0s 184us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 337.8215 - acc: 0.2700\n",
      "12/12 [==============================] - 2s 180ms/step\n",
      "100/100 [==============================] - 0s 178us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 338.1423 - acc: 0.3300\n",
      "12/12 [==============================] - 2s 182ms/step\n",
      "100/100 [==============================] - 0s 173us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 338.0453 - acc: 0.1300\n",
      "12/12 [==============================] - 2s 185ms/step\n",
      "100/100 [==============================] - 0s 166us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 500.3528 - acc: 0.6200\n",
      "12/12 [==============================] - 2s 189ms/step\n",
      "100/100 [==============================] - 0s 181us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 497.5108 - acc: 0.3400\n",
      "12/12 [==============================] - 2s 193ms/step\n",
      "100/100 [==============================] - 0s 151us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 499.5883 - acc: 0.3400\n",
      "12/12 [==============================] - 2s 195ms/step\n",
      "100/100 [==============================] - 0s 243us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 6s 57ms/step - loss: 500.0294 - acc: 0.2200\n",
      "12/12 [==============================] - 3s 215ms/step\n",
      "100/100 [==============================] - 0s 197us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 500.4840 - acc: 0.2200\n",
      "12/12 [==============================] - 2s 208ms/step\n",
      "100/100 [==============================] - 0s 172us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 391.2671 - acc: 0.3400\n",
      "12/12 [==============================] - 2s 204ms/step\n",
      "100/100 [==============================] - 0s 176us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 368.9364 - acc: 0.3300\n",
      "12/12 [==============================] - 2s 206ms/step\n",
      "100/100 [==============================] - 0s 178us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 364.5654 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 208ms/step\n",
      "100/100 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 396.1421 - acc: 0.3200\n",
      "12/12 [==============================] - 3s 218ms/step\n",
      "100/100 [==============================] - 0s 185us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 393.9932 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 216ms/step\n",
      "100/100 [==============================] - 0s 167us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 625.8467 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 216ms/step\n",
      "100/100 [==============================] - 0s 258us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 6s 62ms/step - loss: 630.1320 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 219ms/step\n",
      "100/100 [==============================] - 0s 189us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 65ms/step - loss: 624.8076 - acc: 0.3400\n",
      "12/12 [==============================] - 3s 239ms/step\n",
      "100/100 [==============================] - 0s 268us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 66ms/step - loss: 620.2079 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 226ms/step\n",
      "100/100 [==============================] - 0s 193us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 618.8364 - acc: 0.2700\n",
      "12/12 [==============================] - 3s 229ms/step\n",
      "100/100 [==============================] - 0s 218us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 65ms/step - loss: 653.1057 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 231ms/step\n",
      "100/100 [==============================] - 0s 167us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 66ms/step - loss: 650.5726 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 237ms/step\n",
      "100/100 [==============================] - 0s 189us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 66ms/step - loss: 653.7558 - acc: 0.3700\n",
      "12/12 [==============================] - 3s 237ms/step\n",
      "100/100 [==============================] - 0s 189us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 654.0905 - acc: 0.2700\n",
      "12/12 [==============================] - 3s 241ms/step\n",
      "100/100 [==============================] - 0s 189us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 658.5004 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 245ms/step\n",
      "100/100 [==============================] - 0s 188us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 70ms/step - loss: 622.3370 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 265ms/step\n",
      "100/100 [==============================] - 0s 230us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 637.6669 - acc: 0.3200\n",
      "12/12 [==============================] - 3s 252ms/step\n",
      "100/100 [==============================] - 0s 192us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 71ms/step - loss: 627.4622 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 253ms/step\n",
      "100/100 [==============================] - 0s 199us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 634.4112 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 280ms/step\n",
      "100/100 [==============================] - 0s 200us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 642.9336 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 256ms/step\n",
      "100/100 [==============================] - 0s 206us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 2559.2079 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 260ms/step\n",
      "100/100 [==============================] - 0s 205us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 2560.4298 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 266ms/step\n",
      "100/100 [==============================] - 0s 281us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 2554.0866 - acc: 0.2600\n",
      "12/12 [==============================] - 3s 271ms/step\n",
      "100/100 [==============================] - 0s 211us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 2548.8892 - acc: 0.3400\n",
      "12/12 [==============================] - 3s 271ms/step\n",
      "100/100 [==============================] - 0s 177us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 2570.2602 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 273ms/step\n",
      "100/100 [==============================] - 0s 200us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 3358.1725 - acc: 0.4700\n",
      "12/12 [==============================] - 3s 275ms/step\n",
      "100/100 [==============================] - 0s 174us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 3352.3997 - acc: 0.3400\n",
      "12/12 [==============================] - 3s 276ms/step\n",
      "100/100 [==============================] - 0s 190us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 3383.8933 - acc: 0.1300\n",
      "12/12 [==============================] - 3s 279ms/step\n",
      "100/100 [==============================] - 0s 200us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 3366.5803 - acc: 0.4900\n",
      "12/12 [==============================] - 3s 281ms/step\n",
      "100/100 [==============================] - 0s 184us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 3353.6442 - acc: 0.3400\n",
      "12/12 [==============================] - 4s 312ms/step\n",
      "100/100 [==============================] - 0s 247us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 662.1542 - acc: 0.3300\n",
      "12/12 [==============================] - 3s 288ms/step\n",
      "100/100 [==============================] - 0s 208us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 662.1884 - acc: 0.0300\n",
      "12/12 [==============================] - 4s 293ms/step\n",
      "100/100 [==============================] - 0s 188us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 664.5773 - acc: 0.3300\n",
      "12/12 [==============================] - 4s 294ms/step\n",
      "100/100 [==============================] - 0s 188us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 659.9800 - acc: 0.3400\n",
      "12/12 [==============================] - 4s 298ms/step\n",
      "100/100 [==============================] - 0s 186us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 655.9556 - acc: 0.3300\n",
      "12/12 [==============================] - 4s 305ms/step\n",
      "100/100 [==============================] - 0s 295us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 3356.3943 - acc: 0.6700\n",
      "12/12 [==============================] - 4s 305ms/step\n",
      "100/100 [==============================] - 0s 182us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 3367.4287 - acc: 0.6100\n",
      "12/12 [==============================] - 4s 332ms/step\n",
      "100/100 [==============================] - 0s 241us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 3374.7230 - acc: 0.1600\n",
      "12/12 [==============================] - 4s 310ms/step\n",
      "100/100 [==============================] - 0s 223us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 3377.7928 - acc: 0.3300\n",
      "12/12 [==============================] - 4s 312ms/step\n",
      "100/100 [==============================] - 0s 182us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 3353.9189 - acc: 0.3400\n",
      "12/12 [==============================] - 4s 315ms/step\n",
      "100/100 [==============================] - 0s 214us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 4972.9542 - acc: 0.3400\n",
      "12/12 [==============================] - 4s 322ms/step\n",
      "100/100 [==============================] - 0s 207us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 4995.4000 - acc: 0.1300\n",
      "12/12 [==============================] - 4s 325ms/step\n",
      "100/100 [==============================] - 0s 209us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 4991.4795 - acc: 0.2700\n",
      "12/12 [==============================] - 4s 352ms/step\n",
      "100/100 [==============================] - 0s 246us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 4993.3576 - acc: 0.3500\n",
      "12/12 [==============================] - 4s 365ms/step\n",
      "100/100 [==============================] - 0s 224us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 4977.0669 - acc: 0.3400\n",
      "12/12 [==============================] - 4s 334ms/step\n",
      "100/100 [==============================] - 0s 189us/step\n",
      "Epoch 1/1\n",
      "112/112 [==============================] - 9s 84ms/step - loss: 4.4757 - acc: 0.3036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=None, test_size='default',\n",
       "            train_size=None),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd8957b6320>,\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.01, 1, 10], 'hidden_size_1': [32, 256, 512], 'hidden_size_2': [32, 256, 512]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KerasClassifier(model)\n",
    "ss = StratifiedShuffleSplit(n_splits=5)\n",
    "param_grid = {'C': [.01, 1, 10], \n",
    "              'hidden_size_1': [32, 256, 512],  \n",
    "              'hidden_size_2': [32, 256, 512]}\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=ss)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1150
    },
    "colab_type": "code",
    "id": "RkL73P5KXUvV",
    "outputId": "ca575905-70ef-46f0-9019-5fadf32f7dba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <th>param_hidden_size_1</th>\n",
       "      <th>param_hidden_size_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0.01</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">32</th>\n",
       "      <th>32</th>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">256</th>\n",
       "      <th>32</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">512</th>\n",
       "      <th>32</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">1.00</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">32</th>\n",
       "      <th>32</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">256</th>\n",
       "      <th>32</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">512</th>\n",
       "      <th>32</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">10.00</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">32</th>\n",
       "      <th>32</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">256</th>\n",
       "      <th>32</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">512</th>\n",
       "      <th>32</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 mean_test_score  \\\n",
       "param_C param_hidden_size_1 param_hidden_size_2                    \n",
       "0.01    32                  32                          0.383333   \n",
       "                            256                         0.466667   \n",
       "                            512                         0.466667   \n",
       "        256                 32                          0.483333   \n",
       "                            256                         0.650000   \n",
       "                            512                         0.716667   \n",
       "        512                 32                          0.483333   \n",
       "                            256                         0.716667   \n",
       "                            512                         0.633333   \n",
       "1.00    32                  32                          0.400000   \n",
       "                            256                         0.533333   \n",
       "                            512                         0.400000   \n",
       "        256                 32                          0.416667   \n",
       "                            256                         0.366667   \n",
       "                            512                         0.400000   \n",
       "        512                 32                          0.533333   \n",
       "                            256                         0.383333   \n",
       "                            512                         0.533333   \n",
       "10.00   32                  32                          0.333333   \n",
       "                            256                         0.333333   \n",
       "                            512                         0.400000   \n",
       "        256                 32                          0.333333   \n",
       "                            256                         0.300000   \n",
       "                            512                         0.366667   \n",
       "        512                 32                          0.266667   \n",
       "                            256                         0.466667   \n",
       "                            512                         0.433333   \n",
       "\n",
       "                                                 mean_train_score  \n",
       "param_C param_hidden_size_1 param_hidden_size_2                    \n",
       "0.01    32                  32                              0.364  \n",
       "                            256                             0.454  \n",
       "                            512                             0.470  \n",
       "        256                 32                              0.482  \n",
       "                            256                             0.626  \n",
       "                            512                             0.722  \n",
       "        512                 32                              0.512  \n",
       "                            256                             0.716  \n",
       "                            512                             0.634  \n",
       "1.00    32                  32                              0.400  \n",
       "                            256                             0.496  \n",
       "                            512                             0.408  \n",
       "        256                 32                              0.456  \n",
       "                            256                             0.424  \n",
       "                            512                             0.406  \n",
       "        512                 32                              0.536  \n",
       "                            256                             0.440  \n",
       "                            512                             0.514  \n",
       "10.00   32                  32                              0.330  \n",
       "                            256                             0.334  \n",
       "                            512                             0.404  \n",
       "        256                 32                              0.326  \n",
       "                            256                             0.334  \n",
       "                            512                             0.348  \n",
       "        512                 32                              0.266  \n",
       "                            256                             0.470  \n",
       "                            512                             0.420  "
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "res = pd.DataFrame(grid.cv_results_)\n",
    "res.pivot_table(index=[\"param_C\", \"param_hidden_size_1\", \"param_hidden_size_2\"],\n",
    "                values=['mean_train_score', \"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vwW4FQaW6_XE",
    "outputId": "fb5cd010-d8cf-493f-e953-3bf5a57c28b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'hidden_size_1': 256, 'hidden_size_2': 512}"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Em6QPpBZ7UNB",
    "outputId": "5f242bc6-ad10-43ec-bc44-a6dd0f0af48a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7166666865348816"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NC8kpbj1V7kL"
   },
   "source": [
    "The best combination of parameters are \"C=1\", \"hidden_size_1=256\", and \"hidden_size_2=512\", with the highest accuracy as 0.71 as the test_mean_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "colab_type": "code",
    "id": "AJhh-0FrZmtP",
    "outputId": "f2da3332-b266-4e09-93d7-9385872fa9a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 12 samples\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 4.4869 - acc: 0.3500 - val_loss: 3.9525 - val_acc: 0.5833\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 293us/step - loss: 3.8741 - acc: 0.5300 - val_loss: 3.5356 - val_acc: 0.8333\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 271us/step - loss: 3.4343 - acc: 0.6900 - val_loss: 3.2552 - val_acc: 0.6667\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 255us/step - loss: 3.1360 - acc: 0.6700 - val_loss: 2.8424 - val_acc: 0.6667\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 257us/step - loss: 2.7095 - acc: 0.8000 - val_loss: 2.6153 - val_acc: 0.5833\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 254us/step - loss: 2.4707 - acc: 0.8200 - val_loss: 2.3505 - val_acc: 0.9167\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 278us/step - loss: 2.2180 - acc: 0.9600 - val_loss: 2.1181 - val_acc: 0.8333\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 295us/step - loss: 2.0222 - acc: 0.8600 - val_loss: 1.9639 - val_acc: 0.9167\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 298us/step - loss: 1.8545 - acc: 0.8900 - val_loss: 1.8271 - val_acc: 0.9167\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 285us/step - loss: 1.6957 - acc: 0.9200 - val_loss: 1.6414 - val_acc: 0.8333\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 276us/step - loss: 1.5572 - acc: 0.9000 - val_loss: 1.5308 - val_acc: 0.9167\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 267us/step - loss: 1.4554 - acc: 0.9000 - val_loss: 1.4125 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 265us/step - loss: 1.3364 - acc: 0.9100 - val_loss: 1.3489 - val_acc: 0.8333\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 262us/step - loss: 1.2592 - acc: 0.9000 - val_loss: 1.2557 - val_acc: 0.9167\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 277us/step - loss: 1.1673 - acc: 0.9200 - val_loss: 1.1772 - val_acc: 0.9167\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 315us/step - loss: 1.0797 - acc: 0.9300 - val_loss: 1.0890 - val_acc: 0.8333\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 309us/step - loss: 1.0279 - acc: 0.9400 - val_loss: 1.0301 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 282us/step - loss: 0.9796 - acc: 0.9200 - val_loss: 1.0718 - val_acc: 0.9167\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 264us/step - loss: 0.9368 - acc: 0.9200 - val_loss: 0.9290 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 282us/step - loss: 0.8604 - acc: 0.9600 - val_loss: 0.8889 - val_acc: 0.8333\n"
     ]
    }
   ],
   "source": [
    "best_model = model(hidden_size_1=grid.best_params_['hidden_size_1'], hidden_size_2=grid.best_params_['hidden_size_2'], optimizer=\"adam\", \n",
    "                   C=grid.best_params_['C'])\n",
    "best_model.history=best_model.fit(X_train, y_train, epochs=20, verbose=1, validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "6yNEFx-n7dJN",
    "outputId": "d062c23d-b2e5-42ac-9f4c-f04d6314b05c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.809\n",
      "Test Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "score = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss: {:.3f}\".format(score[0]))\n",
    "print(\"Test Accuracy: {:.3f}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZkfQZ1yWR_d"
   },
   "source": [
    "Retrain the model with the best combination of parameters, and evaluate its performance on the test set: the test loss in 0.809, and the test accuarcy is 0.974. The high accuracy of the test set might as a result of the small test size. There are only 38 test data in the test set, which is easy to achieve a high accuarcy. However, it also somewhat represents the good performance of the model. Also, since there are too many densed layers in the model, the model finally is a bit overfitting with the such small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "MeREH-WtaY7o",
    "outputId": "69f213bb-f458-40cd-a9f6-79abbac422ef"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEWCAYAAADCeVhIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJSdjjDE+x5KTMcYYn/P/S8drRGDslW8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(best_model.history.history)\n",
    "df[['acc', 'val_acc']].plot()\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "df[['loss', 'val_loss']].plot(linestyle='--', ax=plt.twinx())\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xticks(np.arange(0, 20, step=2))\n",
    "\n",
    "_ = plt.title(\"Model Performance\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw5t1_4/30.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
